#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine natbib_authoryear
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Fast latent variable estimates for new patient data
\end_layout

\begin_layout Standard
Ideally, physicians would like to give patients fast, in-visit risk estimates
 whenever new lab results are acquired.
 A standard implementation of our approach would entail re-running MCMC
 to get updated posteriors for the subject's latent variables, which can
 take hours to complete.
 Instead, we use importance sampling (
\begin_inset CommandInset citation
LatexCommand citealp
key "bishop2006pattern"

\end_inset

, chapter 11) to get fast latent variable posterior estimates.
 This can be combined with MCMC periodically (e.g.
 every two weeks) as more patients are acquired, to update the population-level
 parameter posteriors.
\begin_inset Foot
status open

\begin_layout Plain Layout
This approach is conceptually very similar to the approach of 
\begin_inset CommandInset citation
LatexCommand citet
key "lee2002particle"

\end_inset

, who combine a sequential importane sampling with periodic MCMC to update
 all dynamic parameters.
 The dynamic parameters in their work are analogous to the subject-specific
 parameters in ours.
\begin_inset Note Note
status open

\begin_layout Plain Layout
read their paper!!
\end_layout

\end_inset


\end_layout

\end_inset

 It may also be possible to attain a fast, 
\begin_inset Quotes eld
\end_inset

online
\begin_inset Quotes erd
\end_inset

 update of the population-level parameter posteriors, but there are known
 obstacles to this type of updating which push its solution beyond the scope
 of our current work.
\end_layout

\begin_layout Standard
In order to generate proposal values for importance sampling, we start with
 draws from the posterior of the population-level parameters, obtained by
 fitting model refXX on the previously observed data.
 For each draw, we use the conditional distributions in Equation refXX to
 generate proposed latent variable values for the subject with new data.
 The importance weights for these proposed latent variable values are then
 proportional to the likelihood of the newly acquired data, given the proposed
 parameters and latent variables.
 Such a procedure can be thought of a 1-step version of a sequential importance
 resampler, also known as a particle filter 
\begin_inset CommandInset citation
LatexCommand citep
key "bishop2006pattern"

\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Give more cannonical citation
\end_layout

\end_inset

 Note that proposals can be pre-generated before patients enter the clinic,
 so that only the weights need to be calculated in real time.
 Posterior means for each subject can then be computed in approximately
 2 seconds.
 
\end_layout

\begin_layout Standard
By random chance, some patients will have data such that very few of the
 pre-generated, proposed latent variables values will receive high weights.
 This causes their posterior means to be less stable.
 However, such scenarios can be detected by monitoring the effective sample
 size of the posterior sample, also known as the effective number of particles.
 When this number drops below 500, we repeat our procedure with a larger
 set of pre-generated proposals.
\end_layout

\begin_layout Standard
These fast estimates have a correlation of 0.9950 with the estimates from
 running MCMC to estimate all parameters.
 For reference, estimates from two different runs of the full MCMC have
 a correlation of 0.9993, due to the stochastic nature of the posterior sampling.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Agreement-between-MCMC"

\end_inset

 shows the high degree of agreement between posterior risk estimates from
 MCMC, and from importance sampling.
 We give further details of the importance sampling calculations in the
 supplementary materials .
\end_layout

\begin_layout Standard
Our approach still requires the periodic use of MCMC to update all other
 parameters.
 It is tempting to try to use sequential importance resampling (SIRS) to
 estimate posteriors in a fully online fashion, removing the computation
 costs of periodic MCMC.
 However, such online methods are known to suffer from the problem of 
\begin_inset Quotes eld
\end_inset

degeneracy
\begin_inset Quotes erd
\end_inset

 when the model includes static parameters (e.g.
 population-level parameters) in addition to dynamic parameters (e.g.
 subject-specific latent variables).
 For an intuitive discussion of this degeneracy, see section II of 
\begin_inset CommandInset citation
LatexCommand citet
key "andrieu2005line"

\end_inset

.
 Some proposed alternatives include fixed lag updating methods 
\begin_inset CommandInset citation
LatexCommand citep
key "polson2008practical"

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Polish these citations up.
 Need to read.
\end_layout

\end_inset

; augementation of the static parameters 
\begin_inset CommandInset citation
LatexCommand citep
key "kitagawa1998self"

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Polish these citations up.
 Need to read.
\end_layout

\end_inset

; and variational bayes approaches 
\begin_inset CommandInset citation
LatexCommand citep
key "hoffman2010online_variational_bayes_LDA_text_analysis"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
(more VB from Beka?)
\end_layout

\end_inset

.
 See 
\begin_inset CommandInset citation
LatexCommand citet
key "kantas2014particle"

\end_inset

 for a recent literature review.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /Users/aaronfisher/Dropbox/Future Projects/inHealth Prostate Screening/repo/plots/2015-07-01_compare_fits_manual-edit.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Agreement between MCMC (via JAGS) and Importance Sampling - (!! THIS IS
 A PLACEHOLDER FIGURE !!) for each subject, we plot the posterior mean value
 of 
\begin_inset Formula $\eta_{i}$
\end_inset

 from importance sampling, and from full MCMC.
 The correlation between these two estimates is 0.9950.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Agreement-between-MCMC"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Supplement
\end_layout

\begin_layout Subsection
Importance Sampling Procedure
\end_layout

\begin_layout Standard
For the purposes of this section, we introduce the following abbreviated
 form of the model in XX.
 Let the posterior for our model be 
\begin_inset Formula 
\begin{equation}
p(\theta,b_{1:n}|y_{1:n})\propto\prod_{i=1}^{n}[f(y_{i}|b_{i},\theta)g(b_{i}|\theta)]\pi(\theta)\label{eq:posterior_n}
\end{equation}

\end_inset

 Where 
\begin_inset Formula $y_{i}$
\end_inset

 is the vector of measurements for subject 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $y_{1:n}$
\end_inset

 is the list of measurements for the first 
\begin_inset Formula $n$
\end_inset

 subjects, 
\begin_inset Formula $b_{i}$
\end_inset

 is a vector of latent variables for subject 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $b_{1:n}$
\end_inset

 is a list of latent variables for the first 
\begin_inset Formula $n$
\end_inset

 subjects, 
\begin_inset Formula $\theta$
\end_inset

 contains the population-level parameters, 
\begin_inset Formula $\pi$
\end_inset

 is the prior for 
\begin_inset Formula $\theta$
\end_inset

, and 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 are multivariate distributions coming from the likelihood in XX.
 In this section, we illustrate how importance weighting can be used to
 estimate latent variables for a new subject (indexed by 
\begin_inset Formula $n+1$
\end_inset

) entering the study.
\end_layout

\begin_layout Standard
Our goal is to calculate expectations with respect to the posterior distribution
 based on all 
\begin_inset Formula $n+1$
\end_inset

 subjects (i.e.
 
\begin_inset Formula $p(\theta,b_{1:(n+1)}|y_{1:(n+1)})$
\end_inset

).
 Unfortunately, we cannot immediately draw from this distribution, but we
 can evaluate a function that is proportional to its density (Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:posterior_n"

\end_inset

).
 To carry out importance sampling, we need choose a proposal distribution
 
\begin_inset Formula $q$
\end_inset

 from which to generate candidate values of 
\begin_inset Formula $(\theta,b_{1:(n+1)})$
\end_inset

.
 We use the posterior distribution based on the first 
\begin_inset Formula $n$
\end_inset

 subjects as our proposal distribution.
 This approach is analagous to a 1-step particle filter 
\begin_inset CommandInset citation
LatexCommand citep
key "bishop2006pattern"

\end_inset

.
\begin_inset Formula 
\begin{eqnarray*}
q(\theta,b_{1:(n+1)}) & := & g(b_{n+1}|\theta)p(\theta,b_{1:n}|y_{1:n})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Practically, this consists of taking 
\begin_inset Formula $J$
\end_inset

 draws of 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $b_{1:n}$
\end_inset

 from the previously fitted posterior in Eq 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:posterior_n"

\end_inset

.
 Then, conditional on 
\begin_inset Formula $\theta$
\end_inset

, we draw 
\begin_inset Formula $b_{n+1}$
\end_inset

 from the distribution 
\begin_inset Formula $g$
\end_inset

.
 We index each of the resulting draws as 
\begin_inset Formula $(\theta^{(j)},b_{1:(n+1)}^{(j)})$
\end_inset

, with 
\begin_inset Formula $j=1,\dots,J$
\end_inset

.
 The importance weights 
\begin_inset Formula $w_{j}$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 are then proportional to 
\begin_inset Formula 
\begin{eqnarray*}
w^{(j)} & \propto & \frac{p(\theta^{(j)},b_{1:(n+1)}^{(j)}|y_{1:(n+1)})}{q(\theta^{(j)},b_{1:(n+1)}^{(j)})}\\
 & \propto & \frac{\prod_{i=1}^{n+1}[f(y_{i}|b_{i}^{(j)},\theta^{(j)})g(b_{i}^{(j)}|\theta^{(j)})]\pi(\theta^{(j)})}{g(b_{n+1}^{(j)}|\theta^{(j)})\prod_{i=1}^{n}[f(y_{i}|b_{i}^{(j)},\theta^{(j)})g(b_{i}|\theta^{(j)})]\pi(\theta^{(j)})}\\
 & = & f(y_{i}|b_{i}^{(j)},\theta^{(j)})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
The final weights 
\begin_inset Formula $w^{(j)}$
\end_inset

 are standardized to sum to 1.
 The new posterior for 
\begin_inset Formula $(\theta,b_{1:(n+1)})$
\end_inset

 can then be represented as the mixture distribution satisfying 
\begin_inset Formula $P(\theta=\theta^{(j)},b_{1:(n+1)}=b_{1:(n+1)}^{(j)})=w^{(j)}$
\end_inset

.
 A posterior mean for 
\begin_inset Formula $b_{(n+1)}$
\end_inset

 can be calculated as 
\begin_inset Formula $\sum_{j=1}^{J}w^{(j)}b_{(n+1)}^{(j)}$
\end_inset

.
 The unstandardized weights can also be used in a rejection sampling procedure,
 although we found this approach to be less computationally efficient than
 importance sampling for our scenario.
\end_layout

\begin_layout Subsection
Full model online updates
\end_layout

\begin_layout Standard
We generally propose that importance sampling be used for fast, in-visit
 estimates of patient's latent risk.
 This can be combined with periodic MCMC to update the other latent variables
 and population parameters.
 The issue with this approach is that the computational cost of each MCMC
 step increases as more patients are required, making the total computation
 take no less than quadratic time.
 The task of updating a hierarchical model in constant time is an open problem.
\end_layout

\begin_layout Standard
Some initial work on online updates has been proposed in the field of text
 analysis.
 
\begin_inset CommandInset citation
LatexCommand citet
key "hoffman2010online_variational_bayes_LDA_text_analysis"

\end_inset

 applied a variational Bayesian approach, but this has some problems [need
 to explore/talk to Beka]? 
\begin_inset CommandInset citation
LatexCommand citet
key "canini2009online_sampling_LDA_text_analysis"

\end_inset

 consider online sampling methods for text analysis
\begin_inset Note Note
status open

\begin_layout Plain Layout
exactly the same model?
\end_layout

\end_inset

, and recommend a particle filter approach (also known as Sequential Importance
 Resampling)(Need canonical citation)
\begin_inset Note Note
status open

\begin_layout Plain Layout
cite particle filters
\end_layout

\end_inset

.
 However, all of the online methods considered by 
\begin_inset CommandInset citation
LatexCommand citeauthor
key "canini2009online_sampling_LDA_text_analysis"

\end_inset

 do not perform as well as refitting on the entire dataset, in a non-online
 fashion.
 
\end_layout

\begin_layout Standard
Our model also differs from 
\begin_inset CommandInset citation
LatexCommand citet
key "canini2009online_sampling_LDA_text_analysis"

\end_inset

 in a way that further complicate the use of particle filters.
 Like 
\begin_inset CommandInset citation
LatexCommand citeauthor
key "canini2009online_sampling_LDA_text_analysis"

\end_inset

, we assume that our population distribution is 
\emph on
static
\emph default
 over time.
 In other words, we believe that the population-level parameters do not
 change as we acquire new data.
 The presence of such static parameters is known to cause particle filters
 to break down (see 
\begin_inset CommandInset citation
LatexCommand citet
key "andrieu2005line"

\end_inset

, section II, for an intuitive illustration).
 
\begin_inset CommandInset citation
LatexCommand citeauthor
key "canini2009online_sampling_LDA_text_analysis"

\end_inset

 mitigate
\begin_inset Note Note
status open

\begin_layout Plain Layout
fully solve?
\end_layout

\end_inset

 this issue by analytically integrating out the population-level parameters,
 but this approach is not feasible in our case.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "inHealth"
options "apalike"

\end_inset


\end_layout

\end_body
\end_document
